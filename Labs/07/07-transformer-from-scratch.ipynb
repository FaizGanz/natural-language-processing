{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNH2UBexfN9siMBpYs5T45M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Transformer Implementation from Scratch (Oct 21, 2022)\n","\n","This notebook goes through an implementation of a transformer from scratch.\n","\n","**Note:** this is intended as a teaching tool, not a practical implementation. Some details (e.g., initialization) are simplified."],"metadata":{"id":"MewjjVHyn8p-"}},{"cell_type":"code","source":["from typing import NamedTuple\n","import torch\n","from torch import nn\n","from math import sqrt, sin, cos"],"metadata":{"id":"nSzpb65PntXv","executionInfo":{"status":"ok","timestamp":1666647067584,"user_tz":240,"elapsed":136,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"XsOzOtrInnhk","executionInfo":{"status":"ok","timestamp":1666646953117,"user_tz":240,"elapsed":19,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"outputs":[],"source":["class SiTransConfig(NamedTuple):\n","    \"\"\"Wrapper object representing architectural hyperparameters.\"\"\"\n","    n_vocab: int\n","    d_model: int\n","    d_hidden: int\n","    n_heads: int\n","    n_layers: int\n","    seq_len: int\n","    masked: bool = False\n","    biases: bool = False  # Add biases to the linear transformations.\n","    post_ln: bool = False  # Switch to post layer norm.\n","    scale_scores: bool = False  # Scale the attention weights by a sqrt factor.\n","    rel_embed: bool = False  # Should we used fixed relative positional embeddings instead of learned ones?\n","    p_drop: float = 0.  # Dropout probability."]},{"cell_type":"code","source":["config = SiTransConfig(\n","    n_vocab=10000,\n","    d_model=200,\n","    d_hidden=400,\n","    n_heads=20,\n","    n_layers=6,\n","    seq_len=512,\n","  )"],"metadata":{"id":"2Qxdsua1pEc6","executionInfo":{"status":"ok","timestamp":1666646953120,"user_tz":240,"elapsed":20,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Self Attention\n","\n","Let's implement a self attention mechanism."],"metadata":{"id":"67wCY7DvpaBx"}},{"cell_type":"code","source":["class SiSelfAttention(nn.Module):\n","    def __init__(self, config: SiTransConfig):\n","        super().__init__()\n","        assert config.d_model % config.n_heads == 0\n","        d_head = config.d_model // config.n_heads\n","        self.query = nn.Linear(config.d_model, d_head, bias=config.biases)\n","        self.key = nn.Linear(config.d_model, d_head, bias=config.biases)\n","        self.value = nn.Linear(config.d_model, d_head, bias=config.biases)\n","\n","        self.config = config\n","        self.d_head = d_head\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, encodings):\n","        queries = self.query(encodings)  # [seq_len, d_model / n_heads]\n","        keys = self.key(encodings)  # [seq_len, d_model / n_heads] \n","        values = self.value(encodings)\n","        scores = torch.einsum(\"bti, bsi -> bts\", queries, keys)  # [seq_len, seq_len]\n","\n","        if self.config.scale_scores:\n","            scores = scores / sqrt(self.d_head)\n","\n","        if self.config.masked:\n","            seq_len = scores.size(1)\n","            arange = torch.arange(seq_len, device=queries.device)\n","            mask = arange.unsqueeze(dim=0) <= arange.unsqueeze(dim=1)\n","            scores = mask.unsqueeze(dim=0) * scores\n","\n","        weights = self.softmax(scores)\n","        # Weighted average of values (weighted by weights).\n","        return torch.einsum(\"bts, bsh -> bth\", weights, values)"],"metadata":{"id":"Tywme7c1oYtu","executionInfo":{"status":"ok","timestamp":1666646953124,"user_tz":240,"elapsed":21,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["In the transformer, each column has multiple atttention heads that are pooled in parallel by a linear transformation. We now implement a module to wrap this."],"metadata":{"id":"jtMJYGRzrJt-"}},{"cell_type":"code","source":["class SiMultiHead(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.heads = [SiSelfAttention(config) for _ in range(config.n_heads)]\n","        for idx, head in enumerate(self.heads):\n","            self.add_module(f\"head{idx}\", head)\n","        \n","        self.pooler = torch.nn.Linear(config.d_model, config.d_model, bias=config.biases)\n","        self.lnorm = nn.LayerNorm(config.d_model)\n","        self.dropout = nn.Dropout(config.p_drop)\n","    \n","    def forward(self, encodings):\n","        heads = [head(encodings) for head in self.heads]\n","        outputs = self.pooler(torch.cat(heads, dim=-1))\n","        outputs = self.dropout(outputs)\n","        if not self.config.post_ln:\n","            return self.lnorm(outputs) + encodings\n","        else:\n","            return self.lnorm(outputs + encodings)"],"metadata":{"id":"zJmzVgnmolPV","executionInfo":{"status":"ok","timestamp":1666646953127,"user_tz":240,"elapsed":23,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["batch_size = 64"],"metadata":{"id":"Ucpmy2w74F_c","executionInfo":{"status":"ok","timestamp":1666646953275,"user_tz":240,"elapsed":169,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["attn_sublayer = SiMultiHead(config)\n","inputs = torch.randn(size=[64, config.seq_len, config.d_model])\n","outputs = attn_sublayer(inputs)\n","outputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giSB-Wda38cQ","executionInfo":{"status":"ok","timestamp":1666646956104,"user_tz":240,"elapsed":2832,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}},"outputId":"bc120d66-4ec1-4916-abcf-5d2bcc9fd909"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 512, 200])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### Feedforward Nets"],"metadata":{"id":"TPG7obgapcXQ"}},{"cell_type":"code","source":["class SiFeedforward(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        d_model = config.d_model\n","        d_hidden = config.d_hidden\n","        self.net = nn.Sequential(\n","            nn.Linear(d_model, d_hidden, bias=config.biases),\n","            nn.ReLU(),\n","            nn.Linear(d_hidden, d_model, bias=config.biases),\n","        )\n","        self.lnorm = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(config.p_drop)\n","    \n","    def forward(self, encodings):\n","        outputs = self.net(encodings)\n","        outputs = self.dropout(outputs)\n","        if not self.config.post_ln:\n","            return self.lnorm(outputs) + encodings\n","        else:\n","            return self.lnorm(outputs + encodings)"],"metadata":{"id":"Z126aOEhosWE","executionInfo":{"status":"ok","timestamp":1666646956105,"user_tz":240,"elapsed":9,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["ff_sublayer = SiFeedforward(config)\n","inputs = torch.randn(size=[64, config.seq_len, config.d_model])\n","outputs = ff_sublayer(inputs)\n","outputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJHycyM04d-m","executionInfo":{"status":"ok","timestamp":1666646956476,"user_tz":240,"elapsed":378,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}},"outputId":"dfe22d12-b7ae-4fc2-f1e7-211d39fb259e"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 512, 200])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### Transformer Encoder Stack\n","\n","We now have enough to implement the stack of transformer layers that makes up the transformer encoder (note that this still excludes the initial token and positional embeddings)."],"metadata":{"id":"zO2c_zcNpfjs"}},{"cell_type":"code","source":["class SiLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.heads = SiMultiHead(config)\n","        self.ff = SiFeedforward(config)\n","    \n","    def forward(self, encodings):\n","        return self.ff(self.heads(encodings))"],"metadata":{"id":"H_QYmICyoxMg","executionInfo":{"status":"ok","timestamp":1666646956479,"user_tz":240,"elapsed":14,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["layer = SiLayer(config)\n","inputs = torch.randn(size=[64, config.seq_len, config.d_model])\n","outputs = layer(inputs)\n","outputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lm0gvSTn4zXm","executionInfo":{"status":"ok","timestamp":1666646958775,"user_tz":240,"elapsed":2308,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}},"outputId":"2c0da4b3-7f11-431c-da2d-9c505e399aff"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 512, 200])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["class SiEncoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.layers = nn.ModuleList([SiLayer(config) for _ in range(config.n_layers)])\n","\n","    def forward(self, encodings):\n","        for layer in self.layers:\n","            encodings = layer(encodings)\n","        return encodings"],"metadata":{"id":"laGfjPo_o3X3","executionInfo":{"status":"ok","timestamp":1666646958777,"user_tz":240,"elapsed":16,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["encoder = SiEncoder(config)\n","encoder.to(\"cuda\")\n","inputs = torch.randn(size=[64, config.seq_len, config.d_model])\n","outputs = encoder(inputs)\n","outputs.shape"],"metadata":{"id":"D1P8jNgk5ODa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Positional Embeddings"],"metadata":{"id":"q09jDB0Spjj-"}},{"cell_type":"code","source":["class SiEmbedder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.embed = nn.Embedding(config.n_vocab, config.d_model)\n","        self.pos_embed = nn.Embedding(config.seq_len, config.d_model)\n","\n","        if config.rel_embed:\n","            # Relative positional embeddings taken from https://arxiv.org/pdf/1706.03762.pdf.\n","            self.pos_embed.requires_grad = False\n","            embeddings = self.pos_embed.weight\n","            for pos in range(config.seq_len):\n","                for idx in range(config.d_model // 2):\n","                    embeddings[pos, 2 * idx] = sin(pos / 10000**(2 * idx / config.d_model))\n","                    embeddings[pos, 2 * idx + 1] = cos(pos / 10000**(2 * idx / config.d_model))\n","\n","    def forward(self, token_ids):\n","        _, seq_len = token_ids.size()\n","        embeddings = self.embed(token_ids)\n","        positions = torch.arange(seq_len, device=token_ids.device)\n","        pos_embeddings = self.pos_embed(positions).unsqueeze(dim=0)\n","        return embeddings + pos_embeddings"],"metadata":{"id":"9epnBOSso7Dj","executionInfo":{"status":"ok","timestamp":1666647307785,"user_tz":240,"elapsed":148,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["### Putting it All Together\n","\n","Our encoder-only transformer is then just the composition of the embedding layer with the encoder layer."],"metadata":{"id":"KdiTMnfXplgu"}},{"cell_type":"code","source":["class SiTransformer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.embedder = SiEmbedder(config)\n","        # [batch_size, config.seq_len, config.d_model]\n","        self.encoder = SiEncoder(config)\n","        # [batch_size, config.seq_len, config.d_model]\n","    \n","    def forward(self, token_ids):\n","        embeddings = self.embedder(token_ids)\n","        return self.encoder(embeddings)"],"metadata":{"id":"1iumoubno_70","executionInfo":{"status":"ok","timestamp":1666647465779,"user_tz":240,"elapsed":4,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["small_config = SiTransConfig(\n","    n_vocab=1000,\n","    d_model=50,\n","    d_hidden=100,\n","    n_heads=5,\n","    n_layers=3,\n","    seq_len=32,\n","  )"],"metadata":{"id":"EiPdzo-R7l4i","executionInfo":{"status":"ok","timestamp":1666647506291,"user_tz":240,"elapsed":141,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["transformer = SiTransformer(small_config)\n","tokens = torch.arange(10).unsqueeze(0)\n","print(\"Tokens\", tokens.shape)\n","vecs = transformer.forward(tokens)\n","print(\"Vecs\", vecs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8MDK4Rbpoiw","executionInfo":{"status":"ok","timestamp":1666647532165,"user_tz":240,"elapsed":138,"user":{"displayName":"William Merrill","userId":"00521682070879348599"}},"outputId":"4424e623-9679-4403-d4dd-a7390d297a7a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens torch.Size([1, 10])\n","Vecs torch.Size([1, 10, 50])\n"]}]}]}